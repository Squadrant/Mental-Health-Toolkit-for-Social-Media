{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration ucberkeley-dlab--measuring-hate-speech-f91f636a830ad73c\n",
      "Reusing dataset parquet (C:\\Users\\patri\\.cache\\huggingface\\datasets\\parquet\\ucberkeley-dlab--measuring-hate-speech-f91f636a830ad73c\\0.0.0\\0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ce93a5475a4f8db0fa5edc3a72e67b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Downloads the berkley dataset to be cleaned.\n",
    "import datasets\n",
    "dataset = datasets.load_dataset('ucberkeley-dlab/measuring-hate-speech', 'binary') \n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "#Convert the hate_speech_score into a true or a false\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i,\"hate_speech_score\"] <= 0:\n",
    "        df.loc[i,\"classification\"] = '__label__Acceptable'\n",
    "    else:\n",
    "        df.loc[i,\"classification\"] = '__label__Unacceptable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Train sentiments\n",
      "__label__Acceptable      56071\n",
      "__label__Unacceptable    45596\n",
      "Name: classification, dtype: int64\n",
      "Value counts for Test sentiments\n",
      "__label__Acceptable      18883\n",
      "__label__Unacceptable    15006\n",
      "Name: classification, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Tokenise\n",
    "#df['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in df['text']] \n",
    "# Stem words\n",
    "porter_stemmer = PorterStemmer()\n",
    "#df['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in df['tokenized_text'] ]\n",
    "#Split\n",
    "df['stemmed_tokens']=df['text']\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(df['stemmed_tokens'],df['classification'])\n",
    "print(\"Value counts for Train sentiments\")\n",
    "print(Y_train.value_counts())\n",
    "print(\"Value counts for Test sentiments\")\n",
    "print(Y_test.value_counts())\n",
    "X_train = X_train.reset_index()\n",
    "X_test = X_test.reset_index()\n",
    "Y_train = Y_train.to_frame()\n",
    "Y_train = Y_train.reset_index()\n",
    "Y_test = Y_test.to_frame()\n",
    "Y_test = Y_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the files as txt files, required for fasttext\n",
    "train=pd.concat([Y_train['classification'],X_train['stemmed_tokens']],axis=1)\n",
    "test=pd.concat([Y_test['classification'],X_test['stemmed_tokens']],axis=1)\n",
    "train.to_csv('data.train.txt', sep=' ', index=False,encoding=\"utf-8\")\n",
    "test.to_csv('data.test.txt', sep=' ', index=False,encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__Acceptable', '__label__Unacceptable']\n"
     ]
    }
   ],
   "source": [
    "# fasttext processing\n",
    "import fasttext\n",
    "model = fasttext.train_supervised('data.train.txt')\n",
    "#print(model.words)\n",
    "print(model.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t33889\n",
      "P@1\t0.924\n",
      "R@1\t0.924\n"
     ]
    }
   ],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\" + str(N))\n",
    "    print(\"P@{}\\t{:.3f}\".format(1, p))\n",
    "    print(\"R@{}\\t{:.3f}\".format(1, r))\n",
    "\n",
    "print_results(*model.test('data.test.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "manual_input=\"I had a lovely time at the beach last week, thanks all for coming :)\"\n",
    "print(\"The sentence:\",manual_input,'. Was deemed ',model.predict(manual_input), 'by the model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence: I had a lovely time at the beach last week, thanks all for coming :) . Was deemed  (('__label__Acceptable',), array([0.80991381])) by the model\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
