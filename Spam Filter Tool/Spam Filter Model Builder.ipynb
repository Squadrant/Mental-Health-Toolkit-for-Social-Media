{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Spam Filter Model Builder.ipynb","provenance":[{"file_id":"1o05CHrLxrD60J8H6Or8FPkaeNMnujFjb","timestamp":1650633097262},{"file_id":"16zosTBLfZERohEp5KsOobb46VN6CBKIL","timestamp":1649775927470},{"file_id":"1G-g4VcInOSjitnpmEgupUhjlpeKtjDcu","timestamp":1649429955713}],"collapsed_sections":["ECqlKLOEtggw","IjEvzS8c43Do","B86L8sqc_u0l","h1bhaY52ySK1","9Hh31LGzvGRu","0agPGoFEyuIJ","ZC2ZVQ4nz8js","n9KhMryTX5O7","60gt6Tp3i6JD","1yEM6LBWYS5f","sIYjJ5pjabSV","O8a5sP3vjSFt","Nl83HyueNXbk","1r_3pxZMPVZ2","qxL1QzlJR8ui","C6cUkvRGRPx3"],"authorship_tag":"ABX9TyNdlfKS0STX+k76LGxGyx4Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Google Colab Advice\n","## If you are loading the notifications csv from Google Drive, then you first need to mount your Drive to give access to your files. If you are using the csv locally, ignore this cell."],"metadata":{"id":"ECqlKLOEtggw"}},{"cell_type":"code","source":["# Only needed to access a file stored on google drive (if using google colab)\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DMVl0rkut9en","executionInfo":{"status":"ok","timestamp":1650635492687,"user_tz":-60,"elapsed":69624,"user":{"displayName":"Daisy K","userId":"13649947426619625085"}},"outputId":"97b7823b-430d-41fd-d87c-a4cceccb1920"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["#Load the notifications csv into python"],"metadata":{"id":"IjEvzS8c43Do"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"RV3lRK7vtcCY"},"outputs":[],"source":["import pandas as pd\n","\n","# Read notifications csv file, using the path to your file\n","#   r is needed so slashes are taken as literal\n","file_path = r'/content/drive/MyDrive/4th Year Project/Datasets/Daisy Notifcations.csv'\n","df = pd.read_csv(file_path)"]},{"cell_type":"markdown","source":["#Preprocessing the data\n","## Encode class labels\n","### 0 = Unimportant\n","### 1 = Important"],"metadata":{"id":"B86L8sqc_u0l"}},{"cell_type":"code","source":["from sklearn import preprocessing\n","\n","# Encode the T/F labels as 1/0\n","enc = preprocessing.LabelEncoder().fit(df.Important)\n","# Apply the encoder to the labels column, and store it as 'y'\n","y = enc.transform(df['Important'] )"],"metadata":{"id":"Ht3zX7zw5Akg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Set up the feature vectors"],"metadata":{"id":"h1bhaY52ySK1"}},{"cell_type":"markdown","source":["## Handle the Categorical Data\n","### Rearrange the Names column as separate binary columns\n","\n","E.g.\n","\n","Row  | Names\n","------------- | -------------\n","1  | Bob Bobbington. Charles Charlington\n","2  | Emma Emmington. Bob Bobbington\n","3  | Charles Charlington\n","\n"," to \n","\n","Row  |Bob Bobbington  | Charles Charlington | Emma Emmington\n","------------- |------------- | ------------- | -------------\n","1  |1  | 1  | 0\n","2  |1  | 0  | 1\n","3  |0  | 1  | 0"],"metadata":{"id":"9Hh31LGzvGRu"}},{"cell_type":"code","source":["# Replace the names column values with a list of the names in that notifcation\n","names_lists = [str(names).split(\". \") for _, names in df['Names'].items()]\n","df['Names'] = names_lists"],"metadata":{"id":"7Qk8wK3gCNto"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.preprocessing import MultiLabelBinarizer\n","\n","# Rearrange the Names column as above\n","mlb = MultiLabelBinarizer()\n","df_names = pd.DataFrame(mlb.fit_transform(df['Names']),columns=mlb.classes_, index=df.index)"],"metadata":{"id":"hpN1XVm6TA3X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Rearrange the Channels column as separate one-hot binary columns\n","\n","E.g.\n","\n","Row  | Notification Channel\n","------------- | -------------\n","1  | Comments\n","2  | Tags\n","3  | Tags\n","\n"," to \n","\n","Row  |Comments  | Tags \n","------------- |------------- | -------------\n","1  |1  | 0 \n","2  |0  | 1\n","3  |0  | 1"],"metadata":{"id":"0agPGoFEyuIJ"}},{"cell_type":"code","source":["# Rearrange the Channels column as above\n","df_channels = pd.get_dummies(df['Notification Channel'])"],"metadata":{"id":"NAbObNlYt-dM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Combine the feature parts to produce the categorical feature vectors"],"metadata":{"id":"ZC2ZVQ4nz8js"}},{"cell_type":"code","source":["# Append the Channel binary columns to the Names binary columns\n","X = pd.concat([df_names, df_channels], axis=1)"],"metadata":{"id":"OPT1XOrVmV00"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Split the data into training and testing data"],"metadata":{"id":"n9KhMryTX5O7"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Returns data the format: X_train, X_test, y_train, y_test\n","def split_data(X, y):\n","  # Due to limited data, use 80% of the data to train, and 20% to test\n","  #  Feel free to change this 0.2 size to 0.7 or 0.6 if you have lots of data\n","  return train_test_split(X, y, test_size=0.2, random_state=1)"],"metadata":{"id":"xi8uQF35X8fm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_tr, X_te, y_tr, y_te = split_data(X, y)"],"metadata":{"id":"kYV8RyFxeA3N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Scorer\n","Uses score = (2\\*TPR + 3\\*TNR) for a score out of 5"],"metadata":{"id":"60gt6Tp3i6JD"}},{"cell_type":"code","source":["import sklearn\n","from sklearn.metrics import recall_score as TPR, confusion_matrix as cm, make_scorer\n","\n","# Function to produce a score based on the importance of FPR vs TPR\n","#  Returns 2*TRP + 3*FPR for a score out of 5\n","def rate_model(test_labels, predicted_labels):\n","  # Use sklearn's recall_score function to produce a TPR\n","  tpr = TPR(test_labels, predicted_labels)\n","  # Use sklearns confusion matrix function to get the number of true negatives and false positives\n","  #  Returns data in the form: tn, fp, fn, tp\n","  tn, fp, _, _ = cm(test_labels, predicted_labels).ravel()\n","  tnr = tn/(tn+fp)\n","  score = (2*tpr) + (3*tnr)\n","  return score\n","\n","# Make a scorer that can be used in a grid search\n","scorer = make_scorer(rate_model)"],"metadata":{"id":"B3belu-ki5IU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Get Best Model\n","First each classifier (except for HistGradientBoostingClassifier) undergoes a grid search to fins the best parameters for that classifier. Once the best model is made for each classifier, they are compared based on the scorer above, to find the overall best model for this data."],"metadata":{"id":"2UBmZnCu2cBl"}},{"cell_type":"markdown","source":["### Trainer function for HistGradientBoostingClassifier since it does not use a grid search"],"metadata":{"id":"1yEM6LBWYS5f"}},{"cell_type":"code","source":["def train_model(clf, X, y):\n","  clf = clf.fit(X, y)\n","  return clf"],"metadata":{"id":"ecaEY2nl40XU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### K-NN Grid Search"],"metadata":{"id":"sIYjJ5pjabSV"}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier as KNN\n","\n","# Performs a grid search on KNN models using different numbers of neighbours\n","# Returns the best KNN model\n","def grid_search_knn(X, y):\n","  grid = GridSearch(KNN(), param_grid={'n_neighbors': [3,5,10]}, cv=3, scoring=scorer, n_jobs=-1)\n","  grid = grid.fit(X, y)\n","  print(\"KNN Grid Search Results: \",grid.best_params_)\n","  return grid.best_estimator_"],"metadata":{"id":"gnQ6KVR5adS_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Decision Tree Grid Search"],"metadata":{"id":"O8a5sP3vjSFt"}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier as DecTree\n","\n","# Performs a grid search on Decision tree models using different maximum tree depths\n","# Returns the best Dec Tree model\n","def grid_search_dec_tree(X, y):\n","  grid = GridSearch(DecTree(), param_grid={'max_depth': [3,4,5,6]}, cv=3, scoring=scorer, n_jobs=-1)\n","  grid = grid.fit(X, y)\n","  print(\"Dec Tree Grid Search Results: \",grid.best_params_)\n","  return grid.best_estimator_"],"metadata":{"id":"E6jJp1UgaOdH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### SVM Grid Search\n"],"metadata":{"id":"Nl83HyueNXbk"}},{"cell_type":"code","source":["from sklearn.svm import SVC\n","\n","# Performs a grid search on SVM models using different kernels and regularization values\n","# Returns the best SVM model\n","def grid_search_svm(X, y):\n","  grid = GridSearch(SVC(), param_grid={'kernel': ['linear','poly','rbf','sigmoid'], 'C': [0.5, 1.0, 1.5, 2.0, 2.5]})\n","  grid = grid.fit(X, y)\n","  print(\"SVM Grid Search Results: \",grid.best_params_)\n","  return grid.best_estimator_"],"metadata":{"id":"_tuoEkiUNZ9F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Bernoulli Naive Bayes Grid Search\n","Using Bernoulli since the vectors are binary"],"metadata":{"id":"1r_3pxZMPVZ2"}},{"cell_type":"code","source":["from sklearn.naive_bayes import BernoulliNB as NB\n","\n","# Performs a grid search on Naive Bayes models using different alpha values for smoothing\n","# Returns the best NB model\n","def grid_search_naive_bayes(X, y):\n","  grid = GridSearch(NB(), param_grid={'alpha': range(10)}, cv=3, scoring=scorer, n_jobs=-1)\n","  grid = grid.fit(X, y)\n","  print(\"Naive Bayes Grid Search Results: \",grid.best_params_)\n","  return grid.best_estimator_"],"metadata":{"id":"dQjz0_ayPYzc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Multilayer Perceptron Grid Search"],"metadata":{"id":"qxL1QzlJR8ui"}},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\n","\n","# Performs a grid search on MLP models using different alpha values for varying L2 penalties \n","# Returns the best NB model\n","def grid_search_mlp(X, y):\n","  grid = GridSearch(NB(), param_grid={'alpha': [0.00001, 0.0001, 0.001, 0.01, 0.1]}, cv=3, scoring=scorer, n_jobs=-1)\n","  grid = grid.fit(X, y)\n","  print(\"Multilayer Perceptron Grid Search Results: \",grid.best_params_)\n","  return grid.best_estimator_"],"metadata":{"id":"QAaQq2gVR-Vp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train the best model for each classifier type"],"metadata":{"id":"C6cUkvRGRPx3"}},{"cell_type":"code","source":["from sklearn.model_selection import GridSearchCV as GridSearch\n","from sklearn.ensemble import HistGradientBoostingClassifier as HGB\n","\n","# Use a dictionary to keep track of models\n","models = {}\n","\n","# No grid search used for this classifier\n","models[\"Hist Gradient Boosting Classifier\"] = [train_model(HGB(categorical_features=[0,1]),X_tr, y_tr)]\n","# Use a grid search for best tree depth\n","models[\"Decision Tree\"] = [train_model(grid_search_dec_tree(X_tr, y_tr),X_tr, y_tr)]\n","# Use a grid search for best number of neighbours\n","models[\"KNN\"] = [grid_search_knn(X_tr, y_tr)]\n","# Use a grid search for best kernel and c values\n","models[\"SVM\"] = [grid_search_svm(X_tr, y_tr)]\n","# Use a grid search for best alpha smoothing value\n","models[\"Naive Bayes\"] = [grid_search_naive_bayes(X_tr, y_tr)]\n","# Use a grid search for best alpha L2 penalty value\n","models[\"Multilayer Perceptron\"] = [grid_search_mlp(X_tr, y_tr)]\n"],"metadata":{"id":"Nnb_Rdq85Jbb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650635497829,"user_tz":-60,"elapsed":2871,"user":{"displayName":"Daisy K","userId":"13649947426619625085"}},"outputId":"1833efcf-0aca-422c-e6e9-61dfce0f4734"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dec Tree Grid Search Results:  {'max_depth': 3}\n","KNN Grid Search Results:  {'n_neighbors': 3}\n","SVM Grid Search Results:  {'C': 0.5, 'kernel': 'poly'}\n","Naive Bayes Grid Search Results:  {'alpha': 2}\n","Multilayer Perceptron Grid Search Results:  {'alpha': 1e-05}\n"]}]},{"cell_type":"markdown","source":["## Compare the best of the trained models"],"metadata":{"id":"3OJbFL4vabjy"}},{"cell_type":"code","source":["# Models are trained already on by now\n","\n","def eval_models(models):\n","  best_model = next(iter(models))# just set it as the first model\n","  for m in models:\n","    # Train model\n","    #models[m][0] = train_model(models[m][0], X_tr, y_tr)\n","    #models[m][0] = models[m][0].fit(X_tr, y_tr)\n","    # Test Model\n","    preds = models[m][0].predict(X_te)\n","    # Rate Model\n","    models[m].append(rate_model(y_te, preds))\n","    if (models[best_model][1] < models[m][1]):\n","      best_model = m\n","  return models[best_model]\n","\n","best_model = eval_models(models)"],"metadata":{"id":"Wr4h5-gS6oYZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Save the Best Model\n","If using Google Colab, this model will only save locally in this session. To use the model, download and save it in your relevant directory for using the model."],"metadata":{"id":"n2M06Ah1NWKc"}},{"cell_type":"code","source":["#!pip install joblib\n","import joblib\n","def save_model(clf):\n","  #filename = \"Best_model.joblib\"\n","  filename = \"Spam Filter Model.joblib\"\n","  joblib.dump(clf, filename)\n","\n","save_model(best_model[0])"],"metadata":{"id":"fntqsCntNYdY"},"execution_count":null,"outputs":[]}]}